@article{Beck2016Visual,
  abstract = {Bibiographic data such as collections of scientific articles and citation networks have been studied extensively in information visualization and visual analytics research. Powerful systems have been built to support various types of bibliographic analysis, but they require some training and cannot be used to disseminate the insights gained. In contrast, we focused on developing a more accessible visual analytics system, called SurVis, that is ready to disseminate a carefully surveyed literature collection. The authors of a survey may use our Web-based system to structure and analyze their literature database. Later, readers of the survey can obtain an overview, quickly retrieve specific publications, and reproduce or extend the original bibliographic analysis. Our system employs a set of selectors that enable users to filter and browse the literature collection as well as to control interactive visualizations. The versatile selector concept includes selectors for textual search, filtering by keywords and meta-information, selection and clustering of similar publications, and following citation links. Agreement to the selector is represented by word-sized sparkline visualizations seamlessly integrated into the user interface. Based on an analysis of the analytical reasoning process, we derived requirements for the system. We developed the system in a formative way involving other researchers writing literature surveys. A questionnaire study with 14 visual analytics experts confirms that SurVis meets the initially formulated requirements.},
  author = {Beck, Fabian and Koch, Sebastian and Weiskopf, Daniel},
  doi = {10.1109/TVCG.2015.2467757},
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  keywords = {type:system, visual_analytics, sparklines, information_retrieval, clustering, literature_browser},
  number = {01},
  publisher = {IEEE},
  series = {TVCG},
  title = {Visual Analysis and Dissemination of Scientific Literature Collections with {SurVis}},
  url = {http://www.visus.uni-stuttgart.de/uploads/tx_vispublications/vast15-survis.pdf},
  volume = {22},
  year = {2016}
}

@inproceedings{Chauhan2018,
  author = {Chauhan, Rahul and Ghanshala, Kamal Kumar and Joshi, Ramesh Chandra},
  title = {Convolutional Neural Network ({CNN}) for Image Detection and Recognition},
  booktitle = {2018 First International Conference on Secure Cyber Computing and Communication (ICSCCC)},
  year = {2018},
  pages = {278-282},
  doi = {10.1109/ICSCCC.2018.8703316},
  abstract = {Deep Learning algorithms are designed in such a way that they mimic the function of the human cerebral cortex. These algorithms are representations of deep neural networks i.e. neural networks with many hidden layers. Convolutional neural networks are deep learning algorithms that can train large datasets with millions of parameters, in form of 2D images as input and convolve it with filters to produce the desired outputs. In this article, CNN models are built to evaluate its performance on image recognition and detection datasets. The algorithm is implemented on MNIST and CIFAR-10 dataset and its performance are evaluated. The accuracy of models on MNIST is 99.6 %, CIFAR-10 is using real-time data augmentation and dropout on CPU unit.},
  series = {}
  publisher = {IEEE}
  keywords={type: Article, keywords:Deep Learning, Handwritten digit Recognition, Object Detection, Convolutional Neural Networks, MNIST, CIFAR-10, Dropout, Overfitting, Data Augmentation, Relu}
}

@article{Fang2018,
  author = {Fang, Wei and Zhang, Feihong and Sheng, Victor S. and Ding, Yewen},
  title = {A method for improving {CNN-based} image recognition using {DCGAN}},
  journal = {Computers, Materials \& Continua},
  year = {2018},
  volume = {57},
  number = {1},
  pages = {167-178},
  doi = {10.32604/cmc.2018.02356},
  abstract = {Image recognition has always been a hot research topic in the scientific community and industry. The emergence of convolutional neural networks(CNN) has made this technology turned into research focus on the field of computer vision, especially in image recognition. But it makes the recognition result largely dependent on the number and quality of training samples. Recently, DCGAN has become a frontier method for generating images, sounds, and videos. In this paper, DCGAN is used to generate sample that is difficult to collect and proposed an efficient design method of generating model. We combine DCGAN with CNN for the second time. Use DCGAN to generate samples and training in image recognition model, which based by CNN. This method can enhance the classification model and effectively improve the accuracy of image recognition. In the experiment, we used the radar profile as dataset for 4 categories and achieved satisfactory classification performance. This paper applies image recognition technology to the meteorological field.
},
  series = {}
  keywords={type: Article, keywords: DCGAN, image recognition, CNN, samples}
}

@article{Hossain2019,
  author = {Hossain, Anwar and Sajib, Shahriar Alam},
  title = {Classification of Image using Convolutional Neural Network {(CNN)}},
  journal = {Global Journal of Computer Science and Technology},
  year = {2019},
  volume = {19},
  number = {D2},
  pages = {13-18},
  url = {https://gjcst.com/index.php/gjcst/article/view/476},
  abstract = {Computer vision is concerned with the automatic extraction, analysis, and understanding of useful information from a single image or a sequence of images. We have used Convolutional Neural Networks (CNN) in automatic image classification systems. In most cases, we utilize the features from the top layer of the CNN for classification; however, those features may not contain enough useful information to predict an image correctly. In some cases, features from the lower layer carry more discriminative power than those from the top. Therefore, applying features from a specific layer only to classification seems to be a process that does not utilize learned CNN’s potential discriminant power to its full extent. Because of this property we are in need of fusion of features from multiple layers. We want to create a model with multiple layers that will be able to recognize and classify the images. We want to complete our model by using the concepts of Convolutional Neural Network and CIFAR-10 dataset. Moreover, we will show how MatConvNet can be used to implement our model with CPU training as well as less training time. The objective of our work is to learn and practically apply the concepts of Convolutional Neural Network.},
  doi = {na},
  series = {}
  keywords={type: Article, keywords: convolutional neural network, CIFAR-10 dataset, MatConvNet, relu, softmax}
}

@article{Karangiya2024,
  author = {Karangiya, Anjali and Sharma, Anirudh and Shah, Divax and Badgujar, Kartavya and Thacker, Chintan and Dave, Daninik},
  title = {Automatic location detection based on deep learning},
  journal = {arXiv},
  year = {2024},
  doi = {10.48550/arXiv.2403.10912},
  abstract = {The proliferation of digital images and the advancements in deep learning have paved the way for innovative solutions in various domains, especially in the field of image classification. Our project presents an in- depth study and implementation of an image classification system specifically tailored to identify and classify images of Indian cities. Drawing from an extensive dataset, our model classifies images into five major Indian cities: Ahmedabad, Delhi, Kerala, Kolkata, and Mumbai to recognize the distinct features and characteristics of each city/state. To achieve high precision and recall rates, we adopted two approaches. The first, a vanilla Convolutional Neural Network (CNN) and then we explored the power of transfer learning by leveraging the VGG16 model. The vanilla CNN achieved commendable accuracy and the VGG16 model achieved a test accuracy of 63.6%. Evaluations highlighted the strengths and potential areas of improvement, positioning our model as not only competitive but also scalable for broader applications. With an emphasis on open-source ethos, our work aims to contribute to the community, encouraging further development and diverse applications. Our findings demonstrate the potential applications in tourism, urban planning, and even real-time location identification systems, among others.},
  keywords={type: Article, keywords: Convolutional Neural Network, vanilla CNN, VGG16, Transfer Learning, image classification}
  series = {}
  number = {na}
  pages = {na}
  volume = {na}
}

@article{Lygouras2020,
  author = {Lygouras, Eleftherios},
  title = {Vision and geolocation data combination for precise human detection and tracking in search and rescue operations},
  journal = {International Journal of Intelligence Science},
  year = {2020},
  volume = {10},
  number = {3},
  article = {4},
  doi = {10.4236/ijis.2020.103004},
  abstract = {In this paper, a study and evaluation of the combination of GPS/GNSS tech- niques and advanced image processing algorithms for distressed human de- tection, positioning and tracking, from a fully autonomous Unmanned Aerial Vehicle (UAV)-based rescue support system, are presented. In particular, the issue of human detection both on terrestrial and marine environment under several illumination and background conditions, as the human silhouette in water differs significantly from a terrestrial one, is addressed. A robust ap- proach, including an adaptive distressed human detection algorithm running every N input image frames combined with a much faster tracking algorithm, is proposed. Real time or near-real-time distressed human detection rates achieved, using a single, low cost day/night NIR camera mounted onboard a fully autonomous UAV for Search and Rescue (SAR) operations. Moreover, the generation of our own dataset, for the image processing algorithms train- ing is also presented. Details about both hardware and software configuration as well as the assessment of the proposed approach performance are fully discussed. Last, a comparison of the proposed approach to other human de- tection methods used in the literature is presented.},
  series = {}
  keywords={type: Article, keywords: Distressed Human Detection, Unmanned Aerial Vehicles (UAVs), Search and Rescue (SAR) Operations, Aerial Image Processing, Image Processing Algorithms}
  pages = {na}
}

@article{Tian2020,
  author = {Tian, Youhui},
  title = {Artificial intelligence image recognition method based on convolutional neural network algorithm},
  journal = {IEEE Access},
  year = {2020},
  volume = {8},
  pages = {125731-125744},
  doi = {10.1109/ACCESS.2020.3006097},
  abstract = {As an algorithm with excellent performance, convolutional neural network has been widely used in the field of image processing and achieved good results by relying on its own local receptive fields, weight sharing, pooling, and sparse connections. In order to improve the convergence speed and recognition accuracy of the convolutional neural network algorithm, this paper proposes a new convolutional neural network algorithm. First, a recurrent neural network is introduced into the convolutional neural network, and the deep features of the image are learned in parallel using the convolutional neural network and the recurrent neural network. Secondly, according to the idea of ResNet’s skip convolution layer, a new residual module ShortCut3-ResNet is constructed. Then, a dual optimization model is established to realize the integrated optimization of the convolution and full connection process. Finally, the effects of various parameters of the convolutional neural network on the network performance are analyzed through simulation experiments, and the optimal network parameters of the convolutional neural network are finally set. Experimental results show that the convolutional neural network algorithm proposed in this paper can learn the diverse features of the image, and improve the accuracy of feature extraction and image recognition ability of the convolutional neural network.},
  keywords={type: Article, keywords: Convolutional Neural Network, Artificial Intelligence, Image Recognition, Recurrent Neural Network, ResNet, ShortCut3-ResNet, Dual Optimization}
  series = {na}
  number = {na}
}

@article{Voulodimos2018,
  author = {Voulodimos, Athanasios and Doulamis, Nikolaos and Doulamis, Anastasios and Protopapadakis, Eftychios},
  title = {Deep Learning for Computer Vision: A Brief Review},
  journal = {Computational Intelligence and Neuroscience},
  year = {2018},
  volume = {2018},
  pages = {na},
  doi = {10.1155/2018/7068349},
  abstract = {Over the last years deep learning methods have been shown to outperform previous state-of-the-art machine learning techniques in several fields, with computer vision being one of the most prominent cases. This review paper provides a brief overview of some of the most significant deep learning schemes used in computer vision problems, that is, Convolutional Neural Networks, Deep Boltzmann Machines and Deep Belief Networks, and Stacked Denoising Autoencoders. A brief account of their history, structure, advantages, and limitations is given, followed by a description of their applications in various computer vision tasks, such as object detection, face recognition, action and activity recognition, and human pose estimation. Finally, a brief overview is given of future directions in designing deep learning schemes for computer vision problems and the challenges involved therein.},
  keywords  = {type: Survey paper, keywords: Deep Learning, Computer Vision, Convolutional Neural Networks, Deep Belief Networks, Stacked Denoising Autoencoders, Object Detection, Face Recognition, Action Recognition, Human Pose Estimation}
  number = {7068349}


}

@inbook{Weyand2016,
  author = {Weyand, Tobias and Kostrikov, Ilya and Philbin, James},
  title = {{PlaNet} - Photo geolocation with convolutional neural networks},
  booktitle = {Computer Vision – ECCV 2016},
  publisher = {Springer, Cham},
  year = {2016},
  volume = {9912},
  series = {Lecture Notes in Computer Science},
  doi = {10.1007/978-3-319-46484-8_3},
  keywords={type: Article, keywords: Deep Learning, Convolutional Neural Networks, Photo Geolocation, Image Classification}
  abstract = {Is it possible to build a system to determine the loca- tion where a photo was taken using just its pixels? In gen- eral, the problem seems exceptionally difficult: it is trivial to construct situations where no location can be inferred. Yet images often contain informative cues such as landmarks, weather patterns, vegetation, road markings, and architec- tural details, which in combination may allow one to de- termine an approximate location and occasionally an ex- act location. Websites such as GeoGuessr and View from your Window suggest that humans are relatively good at integrating these cues to geolocate images, especially en- masse. In computer vision, the photo geolocation problem is usually approached using image retrieval methods. In contrast, we pose the problem as one of classification by subdividing the surface of the earth into thousands of multi- scale geographic cells, and train a deep network using mil- lions of geotagged images. While previous approaches only recognize landmarks or perform approximate matching us- ing global image descriptors, our model is able to use and integrate multiple visible cues. We show that the result- ing model, called PlaNet, outperforms previous approaches and even attains superhuman levels of accuracy in some cases. Moreover, we extend our model to photo albums by combining it with a long short-term memory (LSTM) archi- tecture. By learning to exploit temporal coherence to ge- olocate uncertain photos, we demonstrate that this model achieves a 50% performance improvement over the single- image model.}
  pages = {na}
}

@article{Williams2018,
  author = {Williams, Travis and Li, Robert},
  title = {An ensemble of convolutional neural networks using wavelets for image classification},
  journal = {Journal of Software Engineering and Applications},
  year = {2018},
  volume = {11},
  number = {2},
  article = {2},
  doi = {10.4236/jsea.2018.112004},
  abstract = {Machine learning is an integral technology many people utilize in all areas of human life. It is pervasive in modern living worldwide, and has multiple usages. One application is image classification, embraced across many spheres of influence such as business, finance, medicine, etc. to enhance produces, causes, efficiency, etc. This need for more accurate, detail-oriented classifica- tion increases the need for modifications, adaptations, and innovations to Deep Learning Algorithms. This article used Convolutional Neural Networks (CNN) to classify scenes in the CIFAR-10 database, and detect emotions in the KDEF database. The proposed method converted the data to the wavelet domain to attain greater accuracy and comparable efficiency to the spatial domain processing. By dividing image data into subbands, important feature learning occurred over differing low to high frequencies. The combination of the learned low and high frequency features, and processing the fused feature mapping resulted in an advance in the detection accuracy. Comparing the proposed methods to spatial domain CNN and Stacked Denoising Autoen- coder (SDA), experimental findings revealed a substantial increase in accu- racy.},
  series = {}
  keywords={type: Article, keywords: CNN, SDA, Neural Network, Deep Learning, Wavelet, Classification, Fusion, Machine Learning, Object Recognition}
  pages = {na}

}

@inproceedings{Wu2015,
  author = {Wu, Meiyni and Chen, Li},
  title = {Image recognition based on deep learning},
  booktitle = {2015 Chinese Automation Congress (CAC)},
  year = {2015},
  pages = {542-546},
  doi = {10.1109/CAC.2015.7382560},
  publisher = {IEEE Computer Society},
  abstract = {Deep learning is a multilayer neural network learning algorithm which emerged in recent years. It has brought a new wave to machine learning, and making artificial intelligence and human-computer interaction advance with big strides. We applied deep learning to handwritten character recognition, and explored the two mainstream algorithm of deep learning: the Convolutional Neural Network (CNN) and the Deep Belief NetWork (DBN). We conduct the performance evaluation for CNN and DBN on the MNIST database and the real-world handwritten character database. The classification accuracy rate of CNN and DBN on the MNIST database is 99.28% and 98.12% respectively, and on the real-world handwritten character database is 92.91% and 91.66% respectively. The experiment results show that deep learning does have an excellent feature learning ability. It don't need to extract features manually. Deep learning can learn more nature features of the data.},
  series = {}
  keywords={type: Article, keywords: Deep Learning, Artificial Intelligence, Convolutional Neural Network, Deep Belief Network, Handwritten Character Recognition}
}